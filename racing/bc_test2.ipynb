{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 環境作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anubis/miniconda3/envs/env38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gymnasium\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "from imitation.data import rollout\n",
    "from imitation.policies.serialize import load_policy\n",
    "from imitation.util.util import make_vec_env\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
    "from stable_baselines3.common.policies import ActorCriticCnnPolicy\n",
    "\n",
    "from gymnasium.spaces import Box\n",
    "from gymnasium.envs.registration import register\n",
    "import racing_gym\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 走行データをロードする関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def load_expert_data_directory(parent_directory):\n",
    "    # parent_directory内のすべてのディレクトリを取得\n",
    "    subdirectories = [os.path.join(parent_directory, d) for d in os.listdir(parent_directory) if os.path.isdir(os.path.join(parent_directory, d))]\n",
    "    \n",
    "    all_expert_data = []  # すべてのディレクトリのexpert_dataを格納するリスト\n",
    "\n",
    "    for data_path in subdirectories:\n",
    "        # ディレクトリごとにexpert_dataの初期化\n",
    "        expert_data = {'images': [], 'actions': []}\n",
    "\n",
    "        # 画像ファイルに対応するJSONファイルを取得\n",
    "        json_file_list = [json_file for json_file in os.listdir(data_path) if json_file.startswith('record_') and json_file.endswith('.json')]\n",
    "\n",
    "        for json_file in json_file_list:\n",
    "            # レコードのファイルパスを構築\n",
    "            json_path = os.path.join(data_path, json_file)\n",
    "\n",
    "            # レコードの読み込み\n",
    "            try:\n",
    "                with open(json_path, 'r') as json_file:\n",
    "                    record_data = json.load(json_file)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"エラー：{json_path} でJSONファイルが見つかりませんでした。\")\n",
    "                continue\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"エラー：{json_path} のJSONファイルのデコードに失敗しました。\")\n",
    "                continue\n",
    "\n",
    "            # 画像データの読み込み\n",
    "            image_file = record_data.get('cam/image_array', '')  # 画像ファイル名をJSONから取得\n",
    "            image_path = os.path.join(data_path, image_file)\n",
    "            try:\n",
    "                image_data = np.array(Image.open(image_path))\n",
    "            except FileNotFoundError:\n",
    "                print(f\"エラー：{image_path} で画像ファイルが見つかりませんでした。\")\n",
    "                continue\n",
    "\n",
    "            # expert_dataに追加\n",
    "            expert_data['images'].append(image_data)\n",
    "            expert_data['actions'].append([record_data.get('user/angle', 0), record_data.get('user/throttle', 0)])\n",
    "        \n",
    "        # すべてのディレクトリのexpert_dataをリストに追加\n",
    "        all_expert_data.append(expert_data)\n",
    "\n",
    "\n",
    "    return all_expert_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "走行データのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_expert_data = load_expert_data_directory('../../autorace/data/T/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "1310\n"
     ]
    }
   ],
   "source": [
    "print(len(all_expert_data))\n",
    "print(len(all_expert_data[0]['images']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像の型を変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 224, 224)\n",
      "(3, 224, 224)\n",
      "(3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "reshaped_all_expert_data = all_expert_data.copy()\n",
    "# すべてのディレクトリに対して\n",
    "for i in range(len(reshaped_all_expert_data)):\n",
    "    # すべての画像を変換\n",
    "    for j in range(len(reshaped_all_expert_data[i]['images'])):\n",
    "        # 画像の軸の順序を変更\n",
    "        reshaped_image = np.transpose(reshaped_all_expert_data[i]['images'][j], (2, 0, 1))\n",
    "        \n",
    "        # expert_dataに変更を反映\n",
    "        reshaped_all_expert_data[i]['images'][j] = reshaped_image.copy()\n",
    "\n",
    "# 形状を確認\n",
    "print(reshaped_all_expert_data[0]['images'][0].shape)\n",
    "\n",
    "for i in range(len(reshaped_all_expert_data)):\n",
    "    for j in range(len(reshaped_all_expert_data[i]['images'])):\n",
    "        if reshaped_all_expert_data[i]['images'][j].shape != (3, 224, 224):\n",
    "            print(i, j)\n",
    "\n",
    "print(all_expert_data[0]['images'][0].shape)\n",
    "print(reshaped_all_expert_data[0]['images'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "18997\n",
      "3693\n"
     ]
    }
   ],
   "source": [
    "# 訓練用とテスト用のデータを初期化\n",
    "train_expert_data = {'images': [], 'actions': []}\n",
    "test_expert_data = {'images': [], 'actions': []}\n",
    "\n",
    "# 評価用とテスト用のデータに7:3にランダムで分割\n",
    "np.random.shuffle(all_expert_data)\n",
    "split_index = int(len(all_expert_data) * 0.8)\n",
    "print(split_index)\n",
    "\n",
    "# 訓練用とテスト用のデータに分割\n",
    "for i in range(split_index):\n",
    "    train_expert_data['images'] += all_expert_data[i]['images']\n",
    "    train_expert_data['actions'] += all_expert_data[i]['actions']\n",
    "\n",
    "for i in range(split_index, len(all_expert_data)):\n",
    "    test_expert_data['images'] += all_expert_data[i]['images']\n",
    "    test_expert_data['actions'] += all_expert_data[i]['actions']\n",
    "\n",
    "    \n",
    "print(len(train_expert_data['actions']))\n",
    "print(len(test_expert_data['actions']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自作環境の宣言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 'RacingEnv-v3' is successfully registered.\n",
      "Environment 'RacingEnv-v3' is successfully registered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anubis/miniconda3/envs/env38/lib/python3.8/site-packages/gymnasium/envs/registration.py:513: DeprecationWarning: \u001b[33mWARN: The environment RacingEnv-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    }
   ],
   "source": [
    "# 学習用の環境を登録\n",
    "env_id1 = 'RacingEnv-v3'  # あなたの環境の名前に変更してください\n",
    "try:\n",
    "    env_train = gymnasium.make(env_id1, expert_data=train_expert_data)\n",
    "    print(f\"Environment '{env_id1}' is successfully registered.\")\n",
    "except gymnasium.error.Error as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# テスト用の環境を登録\n",
    "env_id2 = 'RacingEnv-v3'\n",
    "try:\n",
    "    env_test = gymnasium.make(env_id2, expert_data=test_expert_data)\n",
    "    print(f\"Environment '{env_id2}' is successfully registered.\")\n",
    "except gymnasium.error.Error as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "venvの宣言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_env():\n",
    "    \"\"\"Helper function to create a single environment. Put any logic here, but make sure to return a RolloutInfoWrapper.\"\"\"\n",
    "    _env = gymnasium.make(\"RacingEnv-v3\", expert_data=train_expert_data)\n",
    "    _env = RolloutInfoWrapper(_env)\n",
    "    return _env\n",
    "\n",
    "venv_train = DummyVecEnv([_make_env for _ in range(4)])\n",
    "\n",
    "def _make_env():\n",
    "    \"\"\"Helper function to create a single environment. Put any logic here, but make sure to return a RolloutInfoWrapper.\"\"\"\n",
    "    _env1 = gymnasium.make(\"RacingEnv-v3\", expert_data=test_expert_data)\n",
    "    _env1 = RolloutInfoWrapper(_env1)\n",
    "    return _env1\n",
    "\n",
    "venv_test = DummyVecEnv([_make_env for _ in range(4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPOアルゴリズムによる事前学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anubis/miniconda3/envs/env38/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward before training: 1898.2730857729912\n",
      "Expert reward: 6752.835627999999\n",
      "Expert reward: 1350.1923039704561\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.ppo import CnnPolicy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "\n",
    "expert = PPO(\n",
    "    policy=CnnPolicy,\n",
    "    env=env_train,\n",
    "    seed=0,\n",
    "    batch_size=64,\n",
    "    ent_coef=0.0,\n",
    "    learning_rate=0.0003,\n",
    "    n_epochs=10,\n",
    "    n_steps=64,\n",
    ")\n",
    "reward, _ = evaluate_policy(expert, env_test, 10)\n",
    "print(f\"Reward before training: {reward}\")\n",
    "\n",
    "\n",
    "# Note: if you followed step 2a, i.e. registered the environment, you can use the environment name directly\n",
    "\n",
    "# expert = PPO(\n",
    "#     policy=MlpPolicy,\n",
    "#     env=\"custom/ObservationMatching-v0\",\n",
    "#     seed=0,\n",
    "#     batch_size=64,\n",
    "#     ent_coef=0.0,\n",
    "#     learning_rate=0.0003,\n",
    "#     n_epochs=10,\n",
    "#     n_steps=64,\n",
    "# )\n",
    "expert.learn(1000)  # Note: set to 100000 to train a proficient expert\n",
    "reward, _ = evaluate_policy(expert, expert.get_env(), 10)\n",
    "print(f\"Expert reward: {reward}\")\n",
    "reward, _ = evaluate_policy(expert, env_test, 10)\n",
    "print(f\"Expert reward: {reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPOポリシーからtransitionsを生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "rollouts = rollout.rollout(\n",
    "    expert,\n",
    "    venv_train,\n",
    "    rollout.make_sample_until(min_timesteps=None, min_episodes=10),\n",
    "    rng=rng,\n",
    ")\n",
    "transitions = rollout.flatten_trajectories(rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44304\n"
     ]
    }
   ],
   "source": [
    "print(len(transitions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imitation.algorithms import bc\n",
    "from imitation.util import logger\n",
    "\n",
    "bc_logger = logger.configure('./log/')\n",
    "bc_trainer = bc.BC(\n",
    "    observation_space=env_train.observation_space,\n",
    "    action_space=env_train.action_space,\n",
    "    demonstrations=transitions,\n",
    "    rng=rng,\n",
    "    policy=ActorCriticCnnPolicy(\n",
    "        observation_space=env_train.observation_space,\n",
    "        action_space=env_train.action_space,\n",
    "        features_extractor_kwargs=dict(features_dim=256),\n",
    "        lr_schedule=lambda _: 0.0003,\n",
    "        ),\n",
    "    batch_size=2048,\n",
    "    device=\"cuda:0\",\n",
    "    custom_logger=bc_logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward before training: 1889.2271804511547\n"
     ]
    }
   ],
   "source": [
    "# 学習前の報酬を確認\n",
    "reward_before_training, _ = evaluate_policy(bc_trainer.policy, venv_test, 10)\n",
    "print(f\"Reward before training: {reward_before_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3batch [00:01,  1.76batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 学習\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mbc_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env38/lib/python3.8/site-packages/imitation/algorithms/bc.py:502\u001b[0m, in \u001b[0;36mBC.train\u001b[0;34m(self, n_epochs, n_batches, on_epoch_end, on_batch_end, log_interval, log_rollouts_venv, log_rollouts_n_episodes, progress_bar, reset_tensorboard)\u001b[0m\n\u001b[1;32m    499\u001b[0m         on_batch_end()\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 502\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[1;32m    503\u001b[0m     batch_num,\n\u001b[1;32m    504\u001b[0m     minibatch_size,\n\u001b[1;32m    505\u001b[0m     num_samples_so_far,\n\u001b[1;32m    506\u001b[0m ), batch \u001b[38;5;129;01min\u001b[39;00m batches_with_stats:\n\u001b[1;32m    507\u001b[0m     obs_tensor: Union[th\u001b[38;5;241m.\u001b[39mTensor, Dict[\u001b[38;5;28mstr\u001b[39m, th\u001b[38;5;241m.\u001b[39mTensor]]\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;66;03m# unwraps the observation if it's a dictobs and converts arrays to tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/env38/lib/python3.8/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/env38/lib/python3.8/site-packages/imitation/algorithms/bc.py:165\u001b[0m, in \u001b[0;36menumerate_batches\u001b[0;34m(batch_it)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prepends batch stats before the batches of a batch iterator.\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m num_samples_so_far \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_batches, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_it):\n\u001b[1;32m    166\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    167\u001b[0m     num_samples_so_far \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size\n",
      "File \u001b[0;32m~/miniconda3/envs/env38/lib/python3.8/site-packages/imitation/algorithms/bc.py:64\u001b[0m, in \u001b[0;36mBatchIteratorWithEpochEndCallback.__iter__.<locals>.batch_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_num \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mislice(itertools\u001b[38;5;241m.\u001b[39mcount(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs):\n\u001b[1;32m     63\u001b[0m     some_batch_was_yielded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_loader:\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m batch\n\u001b[1;32m     66\u001b[0m         some_batch_was_yielded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/env38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/env38/lib/python3.8/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/env38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env38/lib/python3.8/site-packages/imitation/data/types.py:473\u001b[0m, in \u001b[0;36mtransitions_collate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    471\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfos\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfos\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m    472\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stack_maybe_dictobs([sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[0;32m--> 473\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mstack_maybe_dictobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnext_obs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/env38/lib/python3.8/site-packages/imitation/data/types.py:233\u001b[0m, in \u001b[0;36mstack_maybe_dictobs\u001b[0;34m(arrs)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DictObs\u001b[38;5;241m.\u001b[39mstack(arrs)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/env38/lib/python3.8/site-packages/numpy/core/shape_base.py:471\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    469\u001b[0m sl \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m),) \u001b[38;5;241m*\u001b[39m axis \u001b[38;5;241m+\u001b[39m (_nx\u001b[38;5;241m.\u001b[39mnewaxis,)\n\u001b[1;32m    470\u001b[0m expanded_arrays \u001b[38;5;241m=\u001b[39m [arr[sl] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 471\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "bc_trainer.train(n_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
