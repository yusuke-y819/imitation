{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "from imitation.data import rollout\n",
    "from imitation.policies.serialize import load_policy\n",
    "from imitation.util.util import make_vec_env\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
    "\n",
    "from gymnasium.spaces import Box\n",
    "from gymnasium.envs.registration import register\n",
    "import racing_gym\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "from imitation.algorithms import bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def load_expert_data(data_path):\n",
    "    # expert_dataの初期化\n",
    "    expert_data = {'images': [], 'actions': []}\n",
    "    # print(expert_data)\n",
    "    # count = 0\n",
    "\n",
    "    # 画像ファイルに対応するJSONファイルを取得\n",
    "    json_file_list = [json_file for json_file in os.listdir(data_path) if json_file.startswith('record_') and json_file.endswith('.json')]\n",
    "    # print(len(json_file_list))\n",
    "\n",
    "    for json_file in json_file_list:\n",
    "        # count += 1\n",
    "        # print(count)\n",
    "        # print(json_file)\n",
    "\n",
    "        # レコードのファイルパスを構築\n",
    "        json_path = os.path.join(data_path, json_file)\n",
    "        # print(json_path)\n",
    "\n",
    "        # レコードの読み込み\n",
    "        try:\n",
    "            with open(json_path, 'r') as json_file:\n",
    "                record_data = json.load(json_file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"エラー：{json_path} でJSONファイルが見つかりませんでした。\")\n",
    "            continue\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"エラー：{json_path} のJSONファイルのデコードに失敗しました。\")\n",
    "            continue\n",
    "\n",
    "        # 画像データの読み込み\n",
    "        image_file = record_data.get('cam/image_array', '')  # 画像ファイル名をJSONから取得\n",
    "        # print(image_file)\n",
    "        image_path = os.path.join(data_path, image_file)\n",
    "        # print(image_path)\n",
    "        try:\n",
    "            image_data = np.array(Image.open(image_path))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"エラー：{image_path} で画像ファイルが見つかりませんでした。\")\n",
    "            continue\n",
    "\n",
    "        # expert_dataに追加\n",
    "        expert_data['images'].append(image_data)\n",
    "        expert_data['actions'].append([record_data.get('user/angle', 0), record_data.get('user/throttle', 0)])\n",
    "\n",
    "    return expert_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# expert_data_path = '../../Data/autorace/O/tub_9_24-01-09'\n",
    "expert_data_path = '../../autorace/data/tub_9_24-01-09'\n",
    "expert_data = load_expert_data(expert_data_path)\n",
    "print(expert_data['images'][0].shape)\n",
    "reshaped_expert_data = expert_data\n",
    "# すべての画像を変換\n",
    "for i in range(len(reshaped_expert_data['images'])):\n",
    "    # 画像の軸の順序を変更\n",
    "    reshaped_image = np.transpose(reshaped_expert_data['images'][i], (2, 0, 1))\n",
    "    \n",
    "    # expert_dataに変更を反映\n",
    "    reshaped_expert_data['images'][i] = reshaped_image\n",
    "\n",
    "# 形状を確認\n",
    "print(reshaped_expert_data['images'][0].shape)\n",
    "\n",
    "for i in range(len(reshaped_expert_data['images'])):\n",
    "    if reshaped_expert_data['images'][i].shape != (3, 224, 224):\n",
    "        print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imitation.algorithms import bc\n",
    "recon_bc = bc.reconstruct_policy('./model/bc_policy_24-02-07_e60_cnn_1', device='cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActorCriticCnnPolicy(\n",
      "  (features_extractor): NatureCNN(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=36864, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (pi_features_extractor): NatureCNN(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=36864, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (vf_features_extractor): NatureCNN(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=36864, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (mlp_extractor): MlpExtractor(\n",
      "    (policy_net): Sequential()\n",
      "    (value_net): Sequential()\n",
      "  )\n",
      "  (action_net): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(recon_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
