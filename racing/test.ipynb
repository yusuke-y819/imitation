{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch2trt import torch2trt\n",
    "from imitation.algorithms import bc\n",
    "from imitation.util import util\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def load_expert_data(data_path):\n",
    "    # expert_dataの初期化\n",
    "    expert_data = {'images': [], 'actions': []}\n",
    "    # print(expert_data)\n",
    "    # count = 0\n",
    "\n",
    "    # 画像ファイルに対応するJSONファイルを取得\n",
    "    json_file_list = [json_file for json_file in os.listdir(data_path) if json_file.startswith('record_') and json_file.endswith('.json')]\n",
    "    # print(len(json_file_list))\n",
    "\n",
    "    for json_file in json_file_list:\n",
    "        # count += 1\n",
    "        # print(count)\n",
    "        # print(json_file)\n",
    "\n",
    "        # レコードのファイルパスを構築\n",
    "        json_path = os.path.join(data_path, json_file)\n",
    "        # print(json_path)\n",
    "\n",
    "        # レコードの読み込み\n",
    "        try:\n",
    "            with open(json_path, 'r') as json_file:\n",
    "                record_data = json.load(json_file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"エラー：{json_path} でJSONファイルが見つかりませんでした。\")\n",
    "            continue\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"エラー：{json_path} のJSONファイルのデコードに失敗しました。\")\n",
    "            continue\n",
    "\n",
    "        # 画像データの読み込み\n",
    "        image_file = record_data.get('cam/image_array', '')  # 画像ファイル名をJSONから取得\n",
    "        # print(image_file)\n",
    "        image_path = os.path.join(data_path, image_file)\n",
    "        # print(image_path)\n",
    "        try:\n",
    "            image_data = np.array(Image.open(image_path))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"エラー：{image_path} で画像ファイルが見つかりませんでした。\")\n",
    "            continue\n",
    "\n",
    "        # expert_dataに追加\n",
    "        expert_data['images'].append(image_data)\n",
    "        expert_data['actions'].append([record_data.get('user/angle', 0), record_data.get('user/throttle', 0)])\n",
    "\n",
    "    return expert_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# expert_data_path = '../../Data/autorace/O/tub_9_24-01-09'\n",
    "expert_data_path = '../../autorace/data/tub_9_24-01-09'\n",
    "expert_data = load_expert_data(expert_data_path)\n",
    "print(expert_data['images'][0].shape)\n",
    "reshaped_expert_data = expert_data\n",
    "# すべての画像を変換\n",
    "for i in range(len(reshaped_expert_data['images'])):\n",
    "    # 画像の軸の順序を変更\n",
    "    reshaped_image = np.transpose(reshaped_expert_data['images'][i], (2, 0, 1))\n",
    "    \n",
    "    # expert_dataに変更を反映\n",
    "    reshaped_expert_data['images'][i] = reshaped_image\n",
    "\n",
    "# 形状を確認\n",
    "print(reshaped_expert_data['images'][0].shape)\n",
    "\n",
    "for i in range(len(reshaped_expert_data['images'])):\n",
    "    if reshaped_expert_data['images'][i].shape != (3, 224, 224):\n",
    "        print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Encountered known unsupported method torch.Tensor.float\n",
      "Warning: Encountered known unsupported method torch.ones_like\n",
      "Warning: Encountered known unsupported method torch.broadcast_tensors\n",
      "Warning: Encountered known unsupported method torch.Tensor.all\n",
      "Warning: Encountered known unsupported method torch.Tensor.__bool__\n",
      "Warning: Encountered known unsupported method torch.Tensor.all\n",
      "Warning: Encountered known unsupported method torch.Tensor.__bool__\n",
      "Warning: Encountered known unsupported method torch.empty\n",
      "Warning: Encountered known unsupported method torch.Tensor.normal_\n",
      "Warning: Encountered known unsupported method torch.Tensor.all\n",
      "Warning: Encountered known unsupported method torch.Tensor.__bool__\n"
     ]
    }
   ],
   "source": [
    "# 学習済みのBCモデルを読み込む\n",
    "bc_trainer = bc.reconstruct_policy('./model/bc_trainer_policy')\n",
    "\n",
    "# 保存したpthファイルをtrtファイルに変換\n",
    "dummy_input = torch.randn(1, 3, 224, 224).cuda()\n",
    "# trt_model = torch2trt(bc_trainer, [dummy_input], fp16_mode=True)\n",
    "trt_model = torch2trt(bc_trainer, [dummy_input], fp16_mode=True, max_workspace_size=1<<25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.CUDA_LAUNCH_BLOCKING = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m action \u001b[38;5;241m=\u001b[39m trt_model(observation_tensor)\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mCUDA_LAUNCH_BLOCKING\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env38/lib/python3.8/site-packages/torch/_tensor.py:431\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    428\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env38/lib/python3.8/site-packages/torch/_tensor_str.py:664\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    663\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env38/lib/python3.8/site-packages/torch/_tensor_str.py:595\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    593\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    594\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 595\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    598\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/miniconda3/envs/env38/lib/python3.8/site-packages/torch/_tensor_str.py:347\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    345\u001b[0m     )\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m~/miniconda3/envs/env38/lib/python3.8/site-packages/torch/_tensor_str.py:138\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmasked_select(\n\u001b[0;32m--> 138\u001b[0m         tensor_view, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m tensor_view\u001b[38;5;241m.\u001b[39mne(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "observation_tensor = torch.tensor(reshaped_expert_data['images'][12], dtype=torch.float32)\n",
    "observation_tensor = observation_tensor.unsqueeze(0)\n",
    "action = trt_model(observation_tensor)\n",
    "torch.backends.cuda.CUDA_LAUNCH_BLOCKING=1\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaia-22/miniconda3/envs/env38/lib/python3.8/site-packages/torch/cuda/memory.py:444: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 利用可能なCUDAメモリを確認\n",
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.memory_cached())\n",
    "\n",
    "# CUDAメモリの解放\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 解放後の利用可能なCUDAメモリを再確認\n",
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.memory_cached())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu121\n",
      "12.1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
